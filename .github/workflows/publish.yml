name: Test and Publish
# based on https://github.com/biotite-dev/biotite/blob/main/.github/workflows/test-and-publish.yml
# and https://packaging.python.org/en/latest/guides/publishing-package-distribution-releases-using-github-actions-ci-cd-workflows/
# n.b. the second example automatically creates a release from a tag; we follow biotite in requiring a manual release

on:
  pull_request:
    branches:
      - "main"
  release:
    types:
      - published
  workflow_dispatch:

jobs:

  pre-commit:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v3
    - uses: pre-commit/action@v3.0.1

  # we cache processed CCD; the processing script, and the frequency file.
  # if any ofthese files change, the cache will be invalidated.
  # we upload built wheel, ccd, and frequency file to internal storage
  # so that it can be reused in several CI jobs (via download-artifact)
  build-internal:
    name: Build and test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: '**/pyproject.toml'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          python build_cython.py
      - name: Get current CCD for hashing
        run: wget -P ./src/bio_datasets/structure/library/ https://files.wwpdb.org/pub/pdb/data/monomers/components.cif.gz
      - name: Get current CCD frequency file for hashing
        run: wget -P ./src/bio_datasets/structure/library/ http://ligand-expo.rcsb.org/dictionaries/cc-counts.tdd
      - name: Cache CCD
        uses: actions/cache@v4
        id: cache-ccd
        with:
          path: ./src/bio_datasets/structure/library/
          key: cache-${{ hashFiles('setup_ccd.py') }}-${{ hashFiles('./src/bio_datasets/structure/library/components.cif.gz') }}-${{ hashFiles('./src/bio_datasets/structure/library/cc-counts.tdd') }}
      - name: Build internal CCD
        if: steps.cache-ccd.outputs.cache-hit != 'true'
        run: |
          python setup_ccd.py
      - name: Remove unprocessed CCD
        run: rm ./src/bio_datasets/structure/library/components.cif.gz
      - name: Install build backend
        run: pip install build
      - name: Build distribution
        run: python -m build --wheel
      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: internal-build
          path: ./dist/*.whl
      - name: Upload CCD
        uses: actions/upload-artifact@v4
        with:
          name: ccd
          path: ./src/bio_datasets/structure/library/components.bcif
      - name: Upload CCD frequency file
        uses: actions/upload-artifact@v4
        with:
          name: ccd_freq
          path: ./src/bio_datasets/structure/library/cc-counts.tdd
      - name: Upload CCD residue dictionary
        uses: actions/upload-artifact@v4
        with:
          name: ccd_res_dict
          path: ./src/bio_datasets/structure/library/ccd_residue_dictionary.json
      - name: Test
        run: |
          pytest

  sdist:
    name: Build source distribution for release
    runs-on: ubuntu-latest
    needs:
      - pre-commit
      - build-internal
    steps:
    - uses: actions/checkout@v4
    - name: Add internal CCD to bio_datasets
      uses: actions/download-artifact@v4
      with:
        name: ccd
        path: src/bio_datasets/structure/library/

    - name: Add internal CCD frequency file to bio_datasets
      uses: actions/download-artifact@v4
      with:
        name: ccd_freq
        path: src/bio_datasets/structure/library/

    - name: Add internal CCD residue dictionary to bio_datasets
      uses: actions/download-artifact@v4
      with:
        name: ccd_res_dict
        path: src/bio_datasets/structure/library/

    # passing --sdist to build prevents re-building wheel and just creates tarred source distribution
    - name: Build source distribution
      run: pipx run build --sdist

    - uses: actions/upload-artifact@v4
      with:
        name: release-sdist
        path: dist//*.tar.gz

    - name: Clean dist directory
      run: rm -rf dist

  # uploaded files are listed under the "Assets" section of the release page on GitHub.
  # This section is separate from the source code archives (like .zip or .tar.gz files) that GitHub automatically generates for the release.
  upload-package:
    name: Upload package to GitHub Releases & PyPI]
    if: github.event_name == 'release' && github.event.action == 'published'
    permissions:
      contents: write
      id-token: write  # IMPORTANT: mandatory for trusted publishing
    needs:
      # - pre-commit
      - build-internal
      - sdist

    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/datasets-bio  # Replace <package-name> with your PyPI project name

    steps:
    - uses: actions/download-artifact@v4
      with:
        pattern: release-*
        merge-multiple: true
        path: dist
    - name: List distributions to be uploaded
      run: ls dist
    - name: Upload to GitHub Releases
      uses: softprops/action-gh-release@v2.0.5
      with:
        files: dist//*
    - name: Upload to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1

  # publish-to-testpypi:
  #   name: Publish Python üêç distribution üì¶ to TestPyPI
  #   needs:
  #   - build
  #   runs-on: ubuntu-latest

  #   environment:
  #     name: testpypi
  #     url: https://test.pypi.org/p/<package-name>

  #   permissions:
  #     id-token: write  # IMPORTANT: mandatory for trusted publishing

  #   steps:
  #   - name: Download all the dists
  #     uses: actions/download-artifact@v4
  #     with:
  #       name: python-package-distributions
  #       path: dist/
  #   - name: Publish distribution üì¶ to TestPyPI
  #     uses: pypa/gh-action-pypi-publish@release/v1
  #     with:
  #       repository-url: https://test.pypi.org/legacy/
